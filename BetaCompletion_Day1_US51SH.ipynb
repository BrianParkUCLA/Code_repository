{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7702befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from re import A, S\n",
    "from numpy import maximum\n",
    "\n",
    "\n",
    "import axioma\n",
    "from axioma.assetset import AssetSet, ActionEntry\n",
    "from axioma.account import Account\n",
    "from axioma.accountgroup import AccountGroup\n",
    "from axioma.workspace import DerbyProvider, Workspace\n",
    "from axioma.workspace_element import ElementType\n",
    "from axioma.costmodel import CostModel, CostStructure\n",
    "from axioma.group import Group, Benchmark, Unit\n",
    "from axioma.contentbuilder_group import ContentBuilderBenchmark, ContentBuilderGroup\n",
    "from axioma.riskmodel import RiskModel\n",
    "from axioma.strategy import Strategy, Objective, Target, Scope, MarketImpactType, PenaltyType\n",
    "from axioma.rebalancing import Rebalancing, RebalancingStatus\n",
    "from axioma.multiportfolio_rebalancing import MultiPortfolioRebalancing\n",
    "from axioma.workspace_element import ElementType\n",
    "from axioma.metagroup import Metagroup, DynamicMetagroup\n",
    "from axioma.analytics import Analytics\n",
    "import axioma.workspace_io as handler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142a1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "axioma.ENDPOINT=\"http://localhost:8085/axioma-websrv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    if 'ws' in locals() and ws is not None:\n",
    "        try:\n",
    "            ws.destroy()\n",
    "        except Exception as e:\n",
    "            # AxiomaError when server object is already gone; ignore that case\n",
    "            if \"ResourceNotFoundException\" not in str(e):\n",
    "                raise\n",
    "finally:\n",
    "    if 'ws' in locals():\n",
    "        del ws\n",
    "\n",
    "\n",
    "\n",
    "dates = [\"2024-10-01\",\"2024-10-02\",\"2024-10-03\"]\n",
    "\n",
    "model = \"US51AxiomaSH\"\n",
    "\n",
    "# iterate through dates in dates list\n",
    "\n",
    "############################## CREATE WORKSPACE\n",
    "i=1\n",
    "date = datetime.strptime(dates[i], '%Y-%m-%d').date()\n",
    "next_period_date = datetime.strptime(dates[i+1], '%Y-%m-%d').date()\n",
    "axioma_data_dir = r'C:/Users/jwbpa/Box/Altisma_Data/AxiomaDownloader-3.3.0-with-jre64/output/extractedFiles/database/${yyyy}/${mm}/'\n",
    "db_provider = DerbyProvider(axioma_data_dir,\n",
    "                            risk_models=model,\n",
    "                            include_composites=True,\n",
    "                            next_period_date=next_period_date,\n",
    "                            returns_type=\"Gross Return\")\n",
    "\n",
    "ws = Workspace(f\"BetaCompletion_Day1_US51SH_{dates[i]}\", date, data_provider=db_provider)\n",
    "\n",
    "############################## LOAD DATA\n",
    "\n",
    "ac_df = pd.read_csv(f\"C:/Users/jwbpa/Box/Altisma_Data/Axioma/Example_Optimization/AlphaCapture_Optimized_{dates[i]}.csv\", index_col=\"Name\")\n",
    "ac_account = Account(workspace = ws, \n",
    "        identity = \"AC_Input\", \n",
    "        holdings=ac_df.to_dict()[\"Shares\"], \n",
    "        asset_map=\"Ticker Map\")\n",
    "\n",
    "ae_df = pd.read_csv(f\"C:/Users/jwbpa/Box/Altisma_Data/Axioma/Example_Optimization/big_portfolio_{dates[i-1]}.csv\", index_col=\"Name\")\n",
    "ae_account = Account(workspace = ws, \n",
    "        identity = \"AE_Input\", \n",
    "        holdings=ae_df.to_dict()[\"Shares\"], \n",
    "        asset_map=\"Ticker Map\")\n",
    "\n",
    "\n",
    "\n",
    "net_account=AccountGroup(workspace=ws, identity = \"AE_AC_AGGREGATE\")\n",
    "net_account.add_account(ac_account)\n",
    "net_account.add_account(ae_account)\n",
    "\n",
    "\n",
    "net_long_value = net_account.get_long_value(price_group=\"Price\", exclude_futures=False)\n",
    "net_short_value = net_account.get_short_value(price_group=\"Price\", exclude_futures=False)\n",
    "net_cash_value = net_account.get_total_cash_value(price_group=\"Price\")\n",
    "net_gross_value=net_long_value+net_short_value+net_cash_value\n",
    "\n",
    "ac_long_value = ac_account.get_long_value(price_group=\"Price\", exclude_futures=False)\n",
    "ac_short_value = ac_account.get_short_value(price_group=\"Price\", exclude_futures=False)\n",
    "ac_cash_value = ac_account.get_total_cash_value(price_group=\"Price\")\n",
    "ac_gross_value=ac_long_value+ac_short_value+ac_cash_value\n",
    "\n",
    "ae_long_value = ae_account.get_long_value(price_group=\"Price\", exclude_futures=False)\n",
    "ae_short_value = ae_account.get_short_value(price_group=\"Price\", exclude_futures=False)\n",
    "ae_cash_value = ae_account.get_total_cash_value(price_group=\"Price\")\n",
    "ae_gross_value=ae_long_value+ae_short_value+ae_cash_value\n",
    "\n",
    "\n",
    "# Benchmark\n",
    "handler.load_assets_from_data_provider(workspace=ws, asset_names=[\"SPY\"], asset_map=\"Ticker Map\")\n",
    "# SPY benchmark is referenced via its composition; explicit asset load is unnecessary\n",
    "spy_benchmark = ContentBuilderBenchmark(workspace=ws, identity = \"SPY_Benchmark\", expression = \"'Composition of 37P4NKR33'*1\")\n",
    "\n",
    "\n",
    "## Content Builder Attributes\n",
    "# Content Builder for 60-Day MDV\n",
    "Inv_60_Day_MDV = ContentBuilderGroup(workspace=ws, identity = \"Inv_60_Day_MDV\", expression = \"(1/'60-Day MDV')\")\n",
    "\n",
    "# Content Builder for Account Currency\n",
    "Account_Currency = ContentBuilderGroup(workspace=ws, identity = \"Account_Currency\", expression = \"portfolioAsCurrency('AC_Input')*1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ef9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'strategy' in locals() and strategy is not None:\n",
    "        try:\n",
    "            strategy.destroy()\n",
    "        except Exception as e:\n",
    "            # AxiomaError when server object is already gone; ignore that case\n",
    "            if \"ResourceNotFoundException\" not in str(e):\n",
    "                raise\n",
    "finally:\n",
    "    if 'strategy' in locals():\n",
    "        del strategy\n",
    "\n",
    "\n",
    "############################## DEFINE STRATEGY\n",
    "strategy = Strategy(workspace = ws, \n",
    "                    identity = \"Strategy\", \n",
    "                    allow_shorting=True, \n",
    "                    allow_crossover=False, \n",
    "                    allow_grandfathering=True,\n",
    "                    enable_constraint_hierarchy=True)\n",
    "strategy.set_local_universe(local_universe=list(ac_account.get_holdings().keys()) + [\"CSH_USD__\"])\n",
    "\n",
    "############################## DEFINE OBJECTIVE TERMS\n",
    "ar_term = axioma.strategy.create_risk_term(strategy = strategy, \n",
    "                                            identity = \"activeRisk\", \n",
    "                                            benchmark=Account_Currency,\n",
    "                                            factor_weight=0, \n",
    "                                            risk_model=model,\n",
    "                                            specific_weight=1.0,\n",
    "                                            asset_set=\"MASTER\",\n",
    "                                            qualification=ac_account\n",
    "                                            )\n",
    "tc_term = axioma.strategy.create_market_impact_term(strategy = strategy, \n",
    "                                                    identity = \"marketImpact\",\n",
    "                                                    buy_impact_group=Inv_60_Day_MDV,\n",
    "                                                    sell_impact_group=Inv_60_Day_MDV,\n",
    "                                                    market_impact_type=MarketImpactType.Quadratic\n",
    "                                                    )\n",
    "############################## DEFINE OBJECTIVE FUNCTION\n",
    "terms = OrderedDict()\n",
    "terms[ar_term] = 1.0\n",
    "terms[tc_term] = 1.0\n",
    "obj_fx = Objective(strategy = strategy, \n",
    "                    identity = \"Objective\", \n",
    "                    terms=terms, \n",
    "                    target=Target.Minimize, \n",
    "                    active=True)\n",
    "############################## DEFINE CONSTRAINTS\n",
    "\n",
    "# constraint 1\n",
    "constraint_do_not_trade_ae=axioma.strategy.create_limit_trade_constraint(strategy = strategy,\n",
    "                                                              identity = \"constraintDoNotTradeAE\",\n",
    "                                                              minimum=0,\n",
    "                                                              maximum=0,\n",
    "                                                              scope=Scope.Asset,\n",
    "                                                              unit=Unit.Percent\n",
    ")\n",
    "# add multiselection qualification based on ae_df\n",
    "constraint_do_not_trade_ae.add_selection(element_type=ElementType.AssetSet, element=\"MASTER\", qualification=ae_account)\n",
    "\n",
    "\n",
    "# constraint 2\n",
    "constraint_market=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintMarket\",\n",
    "                                                                                 minimum=-0.1,\n",
    "                                                                                 maximum=0.1,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Selection,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "# add Market Intercept factor \n",
    "market_mgp = ws.get_metagroup(f\"{model}.Market\")\n",
    "for group in market_mgp.get_groups():\n",
    "    constraint_market.add_selection(element_type=ElementType.Group, element=group)\n",
    "\n",
    "\n",
    "\n",
    "# constraint 3\n",
    "constraint_country=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintCountry\",\n",
    "                                                                                 minimum=-0.1,\n",
    "                                                                                 maximum=0.1,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Selection,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "country_mgp = ws.get_metagroup(f\"{model}.Country\")\n",
    "for group in country_mgp.get_groups():\n",
    "    constraint_country.add_selection(element_type=ElementType.Group, element=group)\n",
    "\n",
    "\n",
    "\n",
    "# constraint 4\n",
    "constraint_local=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintLocal\",\n",
    "                                                                                 minimum=-0.1,\n",
    "                                                                                 maximum=0.1,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Selection,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "local_mgp = ws.get_metagroup(f\"{model}.Local\")\n",
    "for group in local_mgp.get_groups():\n",
    "    constraint_local.add_selection(element_type=ElementType.Group, element=group)\n",
    "\n",
    "\n",
    "\n",
    "# constraint 5\n",
    "constraint_currency=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintCurrency\",\n",
    "                                                                                 minimum=-0.1,\n",
    "                                                                                 maximum=0.1,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Selection,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "currency_mgp = ws.get_metagroup(f\"{model}.Currency\")\n",
    "for group in currency_mgp.get_groups():\n",
    "    constraint_currency.add_selection(element_type=ElementType.Group, element=group)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constraint 6\n",
    "constraint_style=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintStyle\",\n",
    "                                                                                 minimum=-0.1,\n",
    "                                                                                 maximum=0.1,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Selection,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "\n",
    "style_mgp = ws.get_metagroup(f\"{model}.Style\")\n",
    "for group in style_mgp.get_groups():\n",
    "    constraint_style.add_selection(element_type=ElementType.Group, element=group)\n",
    "\n",
    "\n",
    "# constraint 7\n",
    "constraint_sector=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintSector\",\n",
    "                                                                                 minimum=-0.1,\n",
    "                                                                                 maximum=0.1,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Selection,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "# add sector factors to multiselection except real estate and consumer discretionary\n",
    "sectors = ws.get_metagroup(f\"{model}.Sectors\") \n",
    "sectors_metagroup_names_ex_real_estate_and_consumer_discretionary = [\n",
    "    i.identity\n",
    "    for i in sectors.get_metagroups()\n",
    "    if i.identity != f\"{model}.Real Estate-S\" and i.identity != f\"{model}.Consumer Discretionary-S\"\n",
    "]\n",
    "\n",
    "for sector in sectors_metagroup_names_ex_real_estate_and_consumer_discretionary:\n",
    "    constraint_sector.add_selection(element_type=ElementType.Metagroup, element=sector)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constraint 8\n",
    "constraint_realestate=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintRealestate\",\n",
    "                                                                                 minimum=-0.1,\n",
    "                                                                                 maximum=0.1,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Selection,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "# add real estate  to multiselection\n",
    "constraint_realestate.add_selection(element_type=ElementType.Metagroup, element=f\"{model}.Real Estate-S\")\n",
    "\n",
    "\n",
    "# constraint 9\n",
    "constraint_consumerdiscretionary=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintConsumerdiscretionary\",\n",
    "                                                                                 minimum=-0.1,\n",
    "                                                                                 maximum=0.1,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Selection,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "# add consumer discretionary to multiselection\n",
    "constraint_consumerdiscretionary.add_selection(element_type=ElementType.Metagroup, element=f\"{model}.Consumer Discretionary-S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constraint 10\n",
    "constraint_factor_aggregate=axioma.strategy.create_limit_holding_constraint(strategy = strategy,\n",
    "                                                                                 identity = \"constraintFactorAggregate\",\n",
    "                                                                                 minimum=-0.5,\n",
    "                                                                                 maximum=0.5,\n",
    "                                                                                 benchmark=spy_benchmark,\n",
    "                                                                                 scope=Scope.Aggregate,\n",
    "                                                                                 unit=Unit.Percent\n",
    "                                                                                 )\n",
    "\n",
    "# add all factors to multiselection\n",
    "rm = ws.get_risk_model(model)\n",
    "for factor in rm.get_factor_names():\n",
    "    constraint_factor_aggregate.add_selection(element_type=ElementType.Group, element=f\"{model}.{factor}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constraint 7\n",
    "budget=axioma.strategy.create_budget_constraint(strategy = strategy,\n",
    "                                                identity = \"budget\",\n",
    "                                                qualification=ac_account,\n",
    "                                                use_budget_value=True\n",
    "                                                )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# constraint 8\n",
    "empty_benchmark = Benchmark(workspace = ws, identity = \"empty benchmark\", values={}, unit = Unit.Currency)\n",
    "\n",
    "\n",
    "sum_squared_weights=axioma.strategy.create_limit_model_deviation_constraint(strategy = strategy,\n",
    "                                                                            identity = \"sumSquaredWeights\",\n",
    "                                                                            maximum=25,\n",
    "                                                                            penalty=400,\n",
    "                                                                            benchmark=empty_benchmark,\n",
    "                                                                            penalty_type=PenaltyType.ScaledQuadratic,\n",
    "                                                                            scope=Scope.Selection,\n",
    "                                                                            unit=Unit.Percent\n",
    "                                                                            )\n",
    "\n",
    "# add NON-CASH ASSETS to selection\n",
    "sum_squared_weights.add_selection(element_type=ElementType.AssetSet, element=\"NON-CASH ASSETS\")\n",
    "\n",
    "\n",
    "############################## SET CONSTRAINT HIERARCHY CONSTRAINTS\n",
    "\n",
    "# strategy.set_constraint_hierarchy({\n",
    "#     \"matchBenchmarkRealestateSectorExposure\": 1,\n",
    "#     \"matchBenchmarkConsumerDiscretionarySectorExposure\": 2,\n",
    "#     \"matchBenchmarkSectorExposure\":3,\n",
    "#     \"sumSquaredWeights\": 4\n",
    "# })\n",
    "\n",
    "try:\n",
    "    if 'rebal' in locals() and rebal is not None:\n",
    "        try:\n",
    "            rebal.destroy()\n",
    "        except Exception as e:\n",
    "            # AxiomaError when server object is already gone; ignore that case\n",
    "            if \"ResourceNotFoundException\" not in str(e):\n",
    "                raise\n",
    "finally:\n",
    "    if 'rebal' in locals():\n",
    "        del rebal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################## CREATE REBALANCING\n",
    "rebal = MultiPortfolioRebalancing(workspace = ws, \n",
    "                    identity=\"BetaCompletion_Rebalancing\", \n",
    "                    strategy=strategy\n",
    "                    )\n",
    "\n",
    "rebal.add_account(ac_account)\n",
    "rebal.add_account(ae_account)\n",
    "\n",
    "rebal.set_reference_size(net_gross_value)\n",
    "#rebal.set_budget_size(1000000)\n",
    "#rebal.set_benchmark_size(1000000)\n",
    "\n",
    "\n",
    "rebal.set_rebalancing_defaults(round_lot_size=1,\n",
    "                               use_cash_for_roundlot=True,\n",
    "                               risk_model=model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "aae783d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DISCOVERED CONSTRAINT IDENTITIES (from strategy) ===\n",
      "  budget                                             [Constraint]\n",
      "  doNotTradeAE                                       [Constraint]\n",
      "  matchBenchmarkAggregateExposure                    [Constraint]\n",
      "  matchBenchmarkConsumerDiscretionarySectorExposure  [Constraint]\n",
      "  matchBenchmarkMarketExposure                       [Constraint]\n",
      "  matchBenchmarkRealestateSectorExposure             [Constraint]\n",
      "  matchBenchmarkSectorExposure                       [Constraint]\n",
      "  matchBenchmarkStyleExposure                        [Constraint]\n",
      "  sumSquaredWeights                                  [Constraint]\n",
      "\n",
      "Resolved preferred names to real identities (order): ['sumSquaredWeights', 'matchBenchmarkRealestateSectorExposure', 'matchBenchmarkConsumerDiscretionarySectorExposure', 'matchBenchmarkSectorExposure', 'matchBenchmarkStyleExposure', 'matchBenchmarkMarketExposure', 'matchBenchmarkAggregateExposure', 'doNotTradeAE', 'budget']\n",
      "\n",
      "=== SUMMARY ===\n",
      "Final status: RelaxedSolutionFound\n",
      "Relaxed (minimal set): ['sumSquaredWeights', 'matchBenchmarkRealestateSectorExposure', 'matchBenchmarkConsumerDiscretionarySectorExposure', 'matchBenchmarkSectorExposure', 'matchBenchmarkStyleExposure', 'matchBenchmarkMarketExposure', 'matchBenchmarkAggregateExposure', 'doNotTradeAE']\n",
      "Hard (explicit): []\n",
      "\n",
      "=== PER-CONSTRAINT hard_violation (vs ORIGINAL hard bounds) ===\n",
      "\n",
      "[sumSquaredWeights]  max hard_violation=0 PERCENT\n",
      "  • None: final=None  applied=(None,None)  violation=None  hard_violation=None PERCENT\n",
      "\n",
      "[matchBenchmarkRealestateSectorExposure]  max hard_violation=0 PERCENT\n",
      "  • None: final=None  applied=(None,None)  violation=None  hard_violation=None PERCENT\n",
      "\n",
      "[matchBenchmarkConsumerDiscretionarySectorExposure]  max hard_violation=0 PERCENT\n",
      "  • None: final=None  applied=(None,None)  violation=None  hard_violation=None PERCENT\n",
      "\n",
      "[matchBenchmarkSectorExposure]  max hard_violation=0 PERCENT\n",
      "  • None: final=None  applied=(None,None)  violation=None  hard_violation=None PERCENT\n",
      "\n",
      "[matchBenchmarkStyleExposure]  max hard_violation=0 PERCENT\n",
      "  • None: final=None  applied=(None,None)  violation=None  hard_violation=None PERCENT\n",
      "\n",
      "[matchBenchmarkMarketExposure]  max hard_violation=0 PERCENT\n",
      "  • None: final=None  applied=(None,None)  violation=None  hard_violation=None PERCENT\n",
      "\n",
      "[matchBenchmarkAggregateExposure]  max hard_violation=0 PERCENT\n",
      "  • None: final=-0.5003068041654196  applied=(-0.5,0.5)  violation=-0.0003068041654196163  hard_violation=None PERCENT\n",
      "\n",
      "[doNotTradeAE]  max hard_violation=0 PERCENT\n",
      "  • None: final=None  applied=(None,None)  violation=None  hard_violation=None PERCENT\n",
      "['multiPortfolioRebalancings', 'BetaCompletion_Rebalancing', 'solution', 'tradeList']\n",
      "\n",
      "Trade list available. Keys: ['TRADES']\n"
     ]
    }
   ],
   "source": [
    "# === ONE-CELL: discover real constraint names -> ordered relaxation (minimal set) -> optional budget diagnostic ===\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Expect these to exist already:\n",
    "try:\n",
    "    _strat = strategy\n",
    "    _rebal = rebal\n",
    "except NameError as e:\n",
    "    raise RuntimeError(\"This cell expects 'strategy' and 'rebal' to be defined before running.\") from e\n",
    "\n",
    "# ---------- status helpers (robust with/without enum import) ----------\n",
    "def _ok_status(st):\n",
    "    s = str(st)\n",
    "    return (\"SolutionFound\" in s) or (\"RelaxedSolutionFound\" in s)\n",
    "\n",
    "def _status_name(st):\n",
    "    s = str(st)\n",
    "    return s.split(\".\")[-1] if \".\" in s else s\n",
    "\n",
    "# ---------- Your policy ----------\n",
    "# Keep these HARD (never relax). Use your *real* identities:\n",
    "NEVER_RELAX = {}  # 'BudgetConstraint' alias is not used in your notebook; real name is 'budget'\n",
    "\n",
    "# Your preferred order (names may be fuzzy-resolved to actual identities discovered below)\n",
    "PREFERRED_ORDER = [\n",
    "    \"sumSquaredWeights\",\n",
    "    \"matchBenchmarkRealestateSectorExposure\",\n",
    "    \"matchBenchmarkConsumerDiscretionarySectorExposure\",\n",
    "    \"matchBenchmarkSectorExposure\",\n",
    "    \"matchBenchmarkStyleExposure\",\n",
    "    \"matchBenchmarkMarketExposure\",\n",
    "    \"matchBenchmarkAggregateExposure\", \n",
    "    \"doNotTradeAE\",\n",
    "    'budget' # last resort\n",
    "]\n",
    "\n",
    "# Optional diagnostic to quantify budget mismatch if still infeasible with hard budget\n",
    "ALLOW_TEMP_BUDGET_DIAG = False  # <-- set to True ONLY to measure how far budget would need to move (does NOT keep it relaxed in final solve)\n",
    "\n",
    "# ---------- Make hierarchy strict & clear any prior hierarchy ----------\n",
    "try:\n",
    "    _strat.set_options(enable_constraint_hierarchy=True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Avoid reusing softened solutions; avoid auto micro-slack\n",
    "try:\n",
    "    _rebal.set_rebalancing_options(use_memento=False, hierarchy_tolerance_value=0.0)\n",
    "except TypeError:\n",
    "    try: _rebal.set_rebalancing_options(use_memento=False)\n",
    "    except Exception: pass\n",
    "    try: _rebal.set_rebalancing_options(hierarchy_tolerance_value=0.0)\n",
    "    except Exception: pass\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    _strat.set_constraint_hierarchy({})\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ---------- Discovery: pull actual constraint objects and identities ----------\n",
    "def _identity_from_obj(c):\n",
    "    # Try attributes\n",
    "    for attr in (\"identity\",\"name\",\"id\",\"_identity\",\"_name\"):\n",
    "        if hasattr(c, attr):\n",
    "            v = getattr(c, attr)\n",
    "            if callable(v):\n",
    "                try: v = v()\n",
    "                except Exception: v = None\n",
    "            if isinstance(v, str) and v.strip():\n",
    "                return v.strip()\n",
    "    # Try common methods\n",
    "    for m in (\"get_identity\",\"get_name\",\"getId\"):\n",
    "        if hasattr(c, m):\n",
    "            try:\n",
    "                v = getattr(c, m)()\n",
    "                if isinstance(v, str) and v.strip():\n",
    "                    return v.strip()\n",
    "            except Exception:\n",
    "                pass\n",
    "    # Try to_dict\n",
    "    if hasattr(c, \"to_dict\"):\n",
    "        try:\n",
    "            d = c.to_dict()\n",
    "            for k in (\"identity\",\"name\",\"id\"):\n",
    "                if k in d and isinstance(d[k], str) and d[k].strip():\n",
    "                    return d[k].strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def discover_constraints(strategy):\n",
    "    discovered = []\n",
    "    # 1) get_constraints()\n",
    "    if hasattr(strategy, \"get_constraints\"):\n",
    "        try:\n",
    "            for c in (strategy.get_constraints() or []):\n",
    "                nm = _identity_from_obj(c)\n",
    "                discovered.append((nm, c.__class__.__name__))\n",
    "        except Exception:\n",
    "            pass\n",
    "    # 2) fallback maps/attrs (very defensive; may duplicate)\n",
    "    for meth in (\"get_constraint_map\",\"get_constraint_names\",\"list_constraints\"):\n",
    "        if hasattr(strategy, meth):\n",
    "            try:\n",
    "                obj = getattr(strategy, meth)()\n",
    "                if isinstance(obj, dict):\n",
    "                    for k, v in obj.items():\n",
    "                        name = str(k) if k is not None else None\n",
    "                        if name: discovered.append((name, getattr(v, \"__class__\", type(v)).__name__))\n",
    "                elif isinstance(obj, (list, tuple, set)):\n",
    "                    for x in obj:\n",
    "                        if isinstance(x, str):\n",
    "                            discovered.append((x, \"\"))\n",
    "                        else:\n",
    "                            nm = _identity_from_obj(x)\n",
    "                            discovered.append((nm, getattr(x, \"__class__\", type(x)).__name__))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # Clean\n",
    "    clean = []\n",
    "    for nm, tp in discovered:\n",
    "        if nm and isinstance(nm, str):\n",
    "            clean.append((nm, tp))\n",
    "    # Deduplicate by name while preferring the first seen type\n",
    "    seen, rows = set(), []\n",
    "    for nm, tp in clean:\n",
    "        if nm not in seen:\n",
    "            rows.append((nm, tp))\n",
    "            seen.add(nm)\n",
    "    return rows\n",
    "\n",
    "rows = discover_constraints(_strat)\n",
    "\n",
    "print(\"\\n=== DISCOVERED CONSTRAINT IDENTITIES (from strategy) ===\")\n",
    "if not rows:\n",
    "    print(\"(None discovered; API may hide them on this object. Continue anyway.)\")\n",
    "else:\n",
    "    w = max(len(r[0]) for r in rows)\n",
    "    for nm, tp in rows:\n",
    "        print(f\"  {nm.ljust(w)}  [{tp}]\")\n",
    "\n",
    "DISCOVERED_NAMES = [nm for nm,_ in rows]\n",
    "\n",
    "# ---------- Resolve your preferred names to real identities (lenient match) ----------\n",
    "def _norm(s): return re.sub(r\"[^a-z0-9]+\", \"\", s.lower()) if isinstance(s, str) else \"\"\n",
    "disc_norm = { _norm(nm): nm for nm in DISCOVERED_NAMES }\n",
    "\n",
    "resolved = []\n",
    "unresolved = []\n",
    "for wanted in PREFERRED_ORDER:\n",
    "    if wanted in DISCOVERED_NAMES:\n",
    "        resolved.append(wanted)\n",
    "        continue\n",
    "    wn = _norm(wanted)\n",
    "    match = disc_norm.get(wn)\n",
    "    if not match:\n",
    "        # lenient: substring either way\n",
    "        for dn_raw in DISCOVERED_NAMES:\n",
    "            dn = _norm(dn_raw)\n",
    "            if wn and (wn in dn or dn in wn):\n",
    "                match = dn_raw\n",
    "                break\n",
    "    if match:\n",
    "        resolved.append(match)\n",
    "    else:\n",
    "        unresolved.append(wanted)\n",
    "\n",
    "# Remove hard set and duplicates from resolved\n",
    "RESOLVED_ORDER = []\n",
    "seen = set()\n",
    "for nm in resolved:\n",
    "    if nm in NEVER_RELAX:  # never relax\n",
    "        continue\n",
    "    if nm not in seen:\n",
    "        RESOLVED_ORDER.append(nm); seen.add(nm)\n",
    "\n",
    "print(\"\\nResolved preferred names to real identities (order):\", RESOLVED_ORDER)\n",
    "if unresolved:\n",
    "    print(\"Could not resolve (check your naming):\", unresolved)\n",
    "\n",
    "# ---------- Helpers for hierarchy/solve/report ----------\n",
    "def _apply_hierarchy(names_in_order):\n",
    "    mapping = OrderedDict((n, i+1) for i, n in enumerate(names_in_order))\n",
    "    _strat.set_constraint_hierarchy(mapping)\n",
    "\n",
    "def _solve():\n",
    "    return _rebal.solve()\n",
    "\n",
    "def _ordered_relax_minimal(order_names):\n",
    "    # Start with nothing relaxable\n",
    "    try: _apply_hierarchy([])\n",
    "    except Exception: pass\n",
    "\n",
    "    relaxed, sol = [], None\n",
    "\n",
    "    # Add one-by-one\n",
    "    for nm in order_names:\n",
    "        relaxed.append(nm)\n",
    "        _apply_hierarchy(relaxed)\n",
    "        try:\n",
    "            s_try = _solve()\n",
    "            if _ok_status(s_try.get_status()):\n",
    "                sol = s_try\n",
    "                break\n",
    "        except Exception:\n",
    "            sol = None\n",
    "            continue\n",
    "\n",
    "    # If still none, try all at once (in this order)\n",
    "    if sol is None and order_names:\n",
    "        _apply_hierarchy(order_names)\n",
    "        try:\n",
    "            s_try = _solve()\n",
    "            if _ok_status(s_try.get_status()):\n",
    "                sol, relaxed = s_try, list(order_names)\n",
    "            else:\n",
    "                return None, []\n",
    "        except Exception:\n",
    "            return None, []\n",
    "\n",
    "    # Reverse-harden to minimal\n",
    "    for nm in list(relaxed)[::-1]:\n",
    "        trial = [x for x in relaxed if x != nm]\n",
    "        _apply_hierarchy(trial)\n",
    "        try:\n",
    "            s2 = _solve()\n",
    "            if _ok_status(s2.get_status()):\n",
    "                sol, relaxed = s2, trial\n",
    "            else:\n",
    "                _apply_hierarchy(relaxed)  # restore\n",
    "        except Exception:\n",
    "            _apply_hierarchy(relaxed)      # restore\n",
    "\n",
    "    return sol, relaxed\n",
    "\n",
    "def _report_hard_violations(solution, focus=None, top_per_constraint=5, base_order=None):\n",
    "    try:\n",
    "        rows = solution.get_constraint_values()\n",
    "    except Exception as e:\n",
    "        print(\"Constraint values unavailable:\", e)\n",
    "        return\n",
    "    if focus:\n",
    "        fset = {n.lower() for n in focus}\n",
    "        rows = [r for r in rows if str(r.get(\"constraint_name\",\"\")).lower() in fset]\n",
    "    by = {}\n",
    "    for r in rows:\n",
    "        by.setdefault(r.get(\"constraint_name\"), []).append(r)\n",
    "\n",
    "    def _order_key(k):\n",
    "        if base_order and k in base_order: return base_order.index(k)\n",
    "        return 10**9\n",
    "\n",
    "    print(\"\\n=== PER-CONSTRAINT hard_violation (vs ORIGINAL hard bounds) ===\")\n",
    "    if not by:\n",
    "        print(\"(No rows returned for the requested constraints.)\")\n",
    "        return\n",
    "\n",
    "    for cname in sorted(by.keys(), key=_order_key):\n",
    "        items = by[cname]\n",
    "        worst = max(items, key=lambda d: abs(d.get(\"hard_violation\") or 0.0))\n",
    "        unit  = worst.get(\"constraint_unit\")\n",
    "        max_hv = abs(worst.get(\"hard_violation\") or 0.0)\n",
    "        print(f\"\\n[{cname}]  max hard_violation={max_hv:.6g} {unit or ''}\")\n",
    "        for r in sorted(items, key=lambda d: abs(d.get(\"hard_violation\") or 0.0), reverse=True)[:top_per_constraint]:\n",
    "            print(\n",
    "                f\"  • {r.get('selection_name')}: \"\n",
    "                f\"final={r.get('final_value')}  \"\n",
    "                f\"applied=({r.get('applied_min')},{r.get('applied_max')})  \"\n",
    "                f\"violation={r.get('violation')}  \"\n",
    "                f\"hard_violation={r.get('hard_violation')} {unit or ''}\"\n",
    "            )\n",
    "# === PATCH: robust \"hard-violation\" reporter for Axioma ConstraintValue objects OR dicts ===\n",
    "import re\n",
    "\n",
    "def _normalize_key(k: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", (k or \"\").lower())\n",
    "\n",
    "def _safe_call(v):\n",
    "    try:\n",
    "        return v() if callable(v) else v\n",
    "    except Exception:\n",
    "        return v\n",
    "\n",
    "def _lookup_attr(row, candidates):\n",
    "    \"\"\"\n",
    "    Try several attribute/method spellings on an object or dict, then do a\n",
    "    case/underscore-insensitive scan of available attributes as a last resort.\n",
    "    \"\"\"\n",
    "    # 1) direct hit on dict\n",
    "    if isinstance(row, dict):\n",
    "        for c in candidates:\n",
    "            if c in row:\n",
    "                return row[c]\n",
    "        # also try normalized match\n",
    "        norm_map = {_normalize_key(k): k for k in row.keys()}\n",
    "        for c in candidates:\n",
    "            nk = _normalize_key(c)\n",
    "            if nk in norm_map:\n",
    "                return row[norm_map[nk]]\n",
    "        return None\n",
    "\n",
    "    # 2) direct attribute/method on object\n",
    "    for c in candidates:\n",
    "        if hasattr(row, c):\n",
    "            return _safe_call(getattr(row, c))\n",
    "\n",
    "    # 3) \"getXxx\" method variants\n",
    "    for c in candidates:\n",
    "        cc = c[0].upper() + c[1:] if c else c\n",
    "        for alt in (f\"get_{c}\", f\"get{cc}\"):\n",
    "            if hasattr(row, alt):\n",
    "                return _safe_call(getattr(row, alt))\n",
    "\n",
    "    # 4) normalized attribute name search\n",
    "    try:\n",
    "        names = dir(row)\n",
    "        norm_map = {_normalize_key(n): n for n in names}\n",
    "        for c in candidates:\n",
    "            nk = _normalize_key(c)\n",
    "            if nk in norm_map:\n",
    "                return _safe_call(getattr(row, norm_map[nk]))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 5) to_dict / toDict fallback\n",
    "    for m in (\"to_dict\", \"toDict\"):\n",
    "        if hasattr(row, m):\n",
    "            try:\n",
    "                d = getattr(row, m)()\n",
    "                if isinstance(d, dict):\n",
    "                    return _lookup_attr(d, candidates)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return None\n",
    "\n",
    "def _row_to_dict(row):\n",
    "    \"\"\"\n",
    "    Normalize a single row (dict OR object) to a dict with consistent keys.\n",
    "    \"\"\"\n",
    "    fields = {\n",
    "        \"constraint_name\": [\"constraint_name\",\"constraintName\",\"name\",\"constraint\",\"constraint_id\",\"constraintId\"],\n",
    "        \"selection_name\":  [\"selection_name\",\"selectionName\",\"selection\",\"bucket\",\"asset\",\"group\",\"groupName\"],\n",
    "        \"final_value\":     [\"final_value\",\"finalValue\",\"value\",\"final\",\"actualValue\",\"measureValue\"],\n",
    "        \"applied_min\":     [\"applied_min\",\"appliedMin\",\"min\",\"appliedLower\",\"lower\",\"lowerBound\",\"appliedLowerBound\"],\n",
    "        \"applied_max\":     [\"applied_max\",\"appliedMax\",\"max\",\"appliedUpper\",\"upper\",\"upperBound\",\"appliedUpperBound\"],\n",
    "        \"violation\":       [\"violation\",\"applied_violation\",\"appliedViolation\",\"slack\"],\n",
    "        \"hard_violation\":  [\"hard_violation\",\"hardViolation\",\"hardSlack\",\"violation_vs_original\",\"violationVsOriginal\"],\n",
    "        \"constraint_unit\": [\"constraint_unit\",\"constraintUnit\",\"unit\",\"units\"],\n",
    "        \"side\":            [\"side\"]\n",
    "    }\n",
    "    out = {}\n",
    "    for k, cands in fields.items():\n",
    "        out[k] = _lookup_attr(row, cands)\n",
    "    return out\n",
    "\n",
    "def _report_hard_violations(solution, focus=None, top_per_constraint=5, base_order=None):\n",
    "    \"\"\"\n",
    "    Print compact per-constraint report of 'hard_violation' (vs ORIGINAL hard bounds),\n",
    "    robust to Axioma returning dicts OR 'ConstraintValue' objects.\n",
    "    \"\"\"\n",
    "    # 1) fetch rows\n",
    "    rows = []\n",
    "    try:\n",
    "        rows = solution.get_constraint_values()\n",
    "    except Exception as e:\n",
    "        print(\"get_constraint_values() failed:\", e)\n",
    "        rows = []\n",
    "\n",
    "    # 2) normalize rows to dicts\n",
    "    norm = [_row_to_dict(r) for r in (rows or [])]\n",
    "    norm = [r for r in norm if r.get(\"constraint_name\")]\n",
    "\n",
    "    # 3) optional focus filter\n",
    "    if focus:\n",
    "        fset = {str(n).lower() for n in focus}\n",
    "        norm = [r for r in norm if str(r.get(\"constraint_name\",\"\")).lower() in fset]\n",
    "\n",
    "    # 4) group by constraint\n",
    "    by = {}\n",
    "    for r in norm:\n",
    "        by.setdefault(r[\"constraint_name\"], []).append(r)\n",
    "\n",
    "    # 5) nothing to show?\n",
    "    print(\"\\n=== PER-CONSTRAINT hard_violation (vs ORIGINAL hard bounds) ===\")\n",
    "    if not by:\n",
    "        print(\"(No rows matched; verify constraint names in 'focus'.)\")\n",
    "        # show quick debug if we can\n",
    "        sample = rows[0] if rows else None\n",
    "        if sample is not None:\n",
    "            print(\"Example row type:\", type(sample))\n",
    "            try:\n",
    "                some = dir(sample)\n",
    "                print(\"Example available attributes (head):\",\n",
    "                      [a for a in some if not a.startswith(\"_\")][:25])\n",
    "            except Exception:\n",
    "                pass\n",
    "        return by\n",
    "\n",
    "    # 6) printing order helper\n",
    "    if base_order is None:\n",
    "        base_order = []\n",
    "    def _order_key(name):\n",
    "        try:\n",
    "            return list(base_order).index(name)\n",
    "        except ValueError:\n",
    "            return 10**9\n",
    "\n",
    "    # 7) emit report\n",
    "    def _absfloat(x):\n",
    "        try:\n",
    "            return abs(float(x))\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "\n",
    "    for cname in sorted(by.keys(), key=_order_key):\n",
    "        items = by[cname]\n",
    "        worst = max(items, key=lambda d: _absfloat(d.get(\"hard_violation\")))\n",
    "        unit  = worst.get(\"constraint_unit\") or \"\"\n",
    "        print(f\"\\n[{cname}]  max hard_violation={_absfloat(worst.get('hard_violation')):.6g} {unit}\")\n",
    "        # Top offenders within the constraint\n",
    "        top = sorted(items, key=lambda d: _absfloat(d.get(\"hard_violation\")), reverse=True)[:top_per_constraint]\n",
    "        for r in top:\n",
    "            print(\"  • {sel}: final={fv}  applied=({mn},{mx})  violation={v}  hard_violation={hv} {u}\".format(\n",
    "                sel=r.get(\"selection_name\"),\n",
    "                fv=r.get(\"final_value\"),\n",
    "                mn=r.get(\"applied_min\"),\n",
    "                mx=r.get(\"applied_max\"),\n",
    "                v=r.get(\"violation\"),\n",
    "                hv=r.get(\"hard_violation\"),\n",
    "                u=unit\n",
    "            ))\n",
    "    return by\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------- RUN: your resolved order ----------\n",
    "sol, relaxed = _ordered_relax_minimal(RESOLVED_ORDER)\n",
    "\n",
    "# ---------- IF STILL infeasible: try adding any other discovered constraints (except hard set) ----------\n",
    "if sol is None:\n",
    "    extras = [nm for nm in DISCOVERED_NAMES if nm not in NEVER_RELAX and nm not in RESOLVED_ORDER]\n",
    "    if extras:\n",
    "        print(\"\\nExpanding relax order with discovered constraints (excluding hard set):\", extras)\n",
    "        sol, relaxed = _ordered_relax_minimal(RESOLVED_ORDER + extras)\n",
    "\n",
    "# ---------- Final report or diagnostic ----------\n",
    "if sol is None:\n",
    "    print(\"\\n=== RESULT: Still infeasible even after relaxing resolved & discovered constraints (except hard set). ===\")\n",
    "    print(\"Likely a hard conflict (often budget vs doNotTradeAE or another hard limit like an exact cardinality).\")\n",
    "    # Optional diagnostic: temporarily allow budget to relax JUST to measure mismatch\n",
    "    if ALLOW_TEMP_BUDGET_DIAG and (\"budget\" in DISCOVERED_NAMES):\n",
    "        print(\"\\n--- DIAGNOSTIC (temporary): allowing 'budget' to relax to measure mismatch ---\")\n",
    "        diag_order = [\"budget\"] + [nm for nm in (RESOLVED_ORDER + extras if 'extras' in locals() else RESOLVED_ORDER) if nm != \"budget\"]\n",
    "        _apply_hierarchy(diag_order)\n",
    "        try:\n",
    "            s_diag = _solve()\n",
    "            if _ok_status(s_diag.get_status()):\n",
    "                print(\"Diagnostic solve succeeded only when 'budget' is relaxable. Here's how far it needed to move:\")\n",
    "                _report_hard_violations(s_diag, focus={\"budget\"})\n",
    "                print(\"\\n(End of diagnostic. Re-run with ALLOW_TEMP_BUDGET_DIAG=False for normal behavior.)\")\n",
    "            else:\n",
    "                print(\"Diagnostic solve still infeasible even with 'budget' relaxable.\")\n",
    "        except Exception as e:\n",
    "            print(\"Diagnostic solve failed:\", e)\n",
    "else:\n",
    "    print(\"\\n=== SUMMARY ===\")\n",
    "    print(\"Final status:\", _status_name(sol.get_status()))\n",
    "    print(\"Relaxed (minimal set):\", relaxed)\n",
    "    print(\"Hard (explicit):\", sorted(NEVER_RELAX))\n",
    "    # === Call it (same way you did before). If you don't have PREFERRED_ORDER defined, pass list(relaxed).\n",
    "    _report_hard_violations(sol, focus=set(relaxed), base_order=PREFERRED_ORDER if \"PREFERRED_ORDER\" in globals() else list(relaxed))\n",
    "\n",
    "\n",
    "    # Optional: trades (safe only when solved)\n",
    "    try:\n",
    "        try:\n",
    "            trades = sol.get_trade_list(include_initial_holdings=False,\n",
    "                                        include_multi_rebal_settings=False,\n",
    "                                        sales_are_negative=True,\n",
    "                                        split_crossover_trades=True)\n",
    "        except TypeError:\n",
    "            trades = sol.get_trade_list(include_initial_holdings=False,\n",
    "                                        include_rebal_settings=False,\n",
    "                                        sales_are_negative=True,\n",
    "                                        split_crossover_trades=True)\n",
    "        print(\"\\nTrade list available. Keys:\", list(trades)[:10])\n",
    "    except Exception as e:\n",
    "        print(\"Trades unavailable:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "449ee467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_constraints [<axioma.strategy.Constraint object at 0x0000021DFB2A4280>, <axioma.strategy.Constraint object at 0x0000021DFB2A54E0>, <axioma.strategy.Constraint object at 0x0000021DFB2A7CB0>, <axioma.strategy.Constraint object at 0x0000021DFB2A6820>, <axioma.strategy.Constraint object at 0x0000021DFCBFB1C0>, <axioma.strategy.Constraint object at 0x0000021DFCBF92B0>, <axioma.strategy.Constraint object at 0x0000021DFCBF9550>, <axioma.strategy.Constraint object at 0x0000021DFCBFB380>, <axioma.strategy.Constraint object at 0x0000021DFCBFB2A0>]\n"
     ]
    }
   ],
   "source": [
    "getters = (\"get_constraint_names\",\"list_constraints\",\"get_constraints\",\"get_constraint_map\")\n",
    "for g in getters:\n",
    "    if hasattr(strategy, g):\n",
    "        try:\n",
    "            print(g, getattr(strategy, g)())\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6a57b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchy applied (relaxable in priority order): ['sumSquaredWeights', 'matchBenchmarkRealestateSectorExposure', 'matchBenchmarkConsumerDiscretionarySectorExposure', 'matchBenchmarkSectorExposure', 'matchBenchmarkStyleExposure', 'matchBenchmarkMarketExposure', 'matchBenchmarkAggregateExposure', 'doNotTradeAE']\n",
      "Hard constraints include: []\n"
     ]
    }
   ],
   "source": [
    "# After the cell above runs\n",
    "# This is just the mapping we sent; Axioma doesn't always offer a getter:\n",
    "print(\"Hierarchy applied (relaxable in priority order):\", relaxed)\n",
    "print(\"Hard constraints include:\", sorted(NEVER_RELAX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## SOLVE REBALANCING\n",
    "sol = rebal.solve()\n",
    "print(sol.get_status())\n",
    "if sol.get_status()==RebalancingStatus.SolutionFound or sol.get_status()==RebalancingStatus.RelaxedSolutionFound:\n",
    "    fh = sol.get_final_holdings(asset_map = \"Ticker Map\")\n",
    "#sol.get_final_holdings(asset_map=None)\n",
    "ae_fh=sol.get_final_account_holdings_for_account(ae_account, asset_map=\"Ticker Map\")\n",
    "ac_fh=sol.get_final_account_holdings_for_account(ac_account, asset_map=\"Ticker Map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60431b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "############################## CALCULATE ANALYTICS - THESE ARE EXAMPLES OF SOME AVAILABLE ANALYTICS\n",
    "# create Analytics object. This will be used to calculate analytics\n",
    "analyzer = Analytics(workspace = ws, price_group=\"Price\", asset_map=\"Ticker Map\")\n",
    "\n",
    "# compute active holdings of final holdings\n",
    "ah = analyzer.compute_active_holdings(holdings=fh, benchmark=spy_benchmark, reference_value=rebal.get_reference_size())\n",
    "\n",
    "# calculate active exposures -> you divide df by reference size to convert from currency values to decimal\n",
    "ah_exposures = pd.DataFrame.from_dict({\"Exposure\":analyzer.compute_factor_exposures(risk_model=model,holdings=ah)})/rebal.get_reference_size()\n",
    "\n",
    "# compute tracking error.\n",
    "tracking_error = analyzer.compute_factors_risk(risk_model=model,holdings=ah)/rebal.get_reference_size()*100\n",
    "\n",
    "\n",
    "########################## Find Idio Return and Risk of final solution next day.\n",
    "# Factor return\n",
    "factor_return_dollar = analyzer.compute_factor_return_contributions(risk_model=model, \n",
    "                                                          metagroup = f\"{model}.Period Returns\",\n",
    "                                                          holdings=ah)\n",
    "\n",
    "# Total return\n",
    "total_return_dollar =analyzer.compute_expected_return(alphas=\"Period Return\", holdings=ah)\n",
    "\n",
    "# Idio return\n",
    "idio_return_dollar = total_return_dollar - factor_return_dollar\n",
    "\n",
    "# Convert dollar to %\n",
    "idio_return_percent = idio_return_dollar / rebal.get_reference_size()*100\n",
    "\n",
    "# Factor risk\n",
    "factor_risk_dollar = analyzer.compute_factors_risk(risk_model=model, holdings=ah)\n",
    "\n",
    "# Total risk\n",
    "total_risk_dollar = analyzer.compute_total_risk(risk_model=model, holdings=ah)\n",
    "\n",
    "# Idio risk\n",
    "idio_risk_dollar = analyzer.compute_specific_risk(risk_model=model, holdings=ah)\n",
    "\n",
    "# Convert dollar to %\n",
    "idio_risk_percent = idio_risk_dollar / rebal.get_reference_size()*100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# write workspace to .wsp file and release license token\n",
    "ws.write(os.getcwd(),file_name=f\"workspace_on_{dates[i]}.wsp\",save_reference=False)\n",
    "ws.destroy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
